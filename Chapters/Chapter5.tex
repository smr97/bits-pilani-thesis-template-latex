% Chapter 1

\chapter{Case study: Infix solvers} % Main chapter title

\label{Chapter5} % For referencing the chapter elsewhere, use \ref{Chapter1}

\lhead{Chapter 5. \emph{Case study: Infix solvers}} % This is for the header on each page - perhaps a shortened title
In order to better comprehend the Rayon API and the Adaptive API, a small case study of infix solvers was carried out. The following problem was solved using sequential and parallel iterators, logs were generated and performance was compared to understand the implications of using these abstract APIs.

%----------------------------------------------------------------------------------------
\section{The problem}
There exists an expression of integers interleaved with the addition or multiplication operator. The objective is to evaluate this expression with the precedence of multiplication over addition and return the integral result.
%----------------------------------------------------------------------------------------
\section{The sequential algorithm}
In order to solve this problem using iterators, it is necessary to do a stateful iteration over the input. The state represents the partial output for the subset of the input that has already been scanned. This can be represented by a tuple in which the first element represents the sum of all partial products encountered, and the second element represents the running partial product. Such a stateful iteration is implemented using the fold function over sequential iterators in Rust.
\subsection{Code}
\begin{verbatim}
fn sequential_solver(inp: &[Token], outp: &mut u64) {
    let ans = inp.iter().fold((0, 1), |tup, elem| match elem {
        Token::Num(i) => (tup.0, tup.1 * *i),
        Token::Mult => tup,
        Token::Add => (tup.0 + tup.1, 1),
    });
    *outp = ans.0 + ans.1
}
\end{verbatim}
%----------------------------------------------------------------------------------------
\section{Parallel variants}
Since the parallel reduction requires an associative binary operator, it is necessary to modify the state representation such that it can capture a partial result over \emph{any} contiguous subset of the input, as opposed to a subset of the input taken invariably from the start. Furthermore, it should be possible to combine two such partial results into one. This intermediate result has hence been defined as a triplet of integers \emph{(a, b, c)} where \emph{a} is the product of all integers that were encountered till the first sum operand, \emph{b} is the sum of all intermediate products except the last one and \emph{c} is the last contiguous product of integers.

This representation is hence initialised as (0, 0, 1) and at the occurence of any integer, \emph{c} is multiplied with that integer. Whenever + is encountered, if \emph{a} is 0, we set \emph{a = c}. Else, we set \emph{b} += \emph{c}. The occurence of * is requires no action.

Combination of two partial results \emph{(a, b, c)} and \emph{(d, e, f)} produces the partial result \emph{(a, b}+\emph{c}*\emph{d}+\emph{e, f)}.

\subsection{Rayon Fold}
The aforementioned stateful iteration can be done over a parallel iterator in the Rayon API. As opposed to a single final state in the sequential fold, Rayon's fold function produces several final states in parallel. This requires a parallel reduction that will be carried out using the classic reduction tree to produce one single result.

In the case of infix solvers, the fold shall produce several such partial results, all of which will be reduced in parallel into one single result which will be in the form \emph{(a, b, c)}, however, it will represent the entire input. Hence, the integral result is trivially computed as \emph{a}+\emph{b}+\emph{c}.
\subsection{Rayon Split}
Another strategy could be to exploit the \emph{par\_split()} function in Rayon to slice the input at all occurence) of the +. These slices invariably represent contiguous products of integers, which can be computed using a nested parallel iterator which carry out a parallel reduction using the binary associative multiply operator. Finally, another parallel reduction using the + operator gives the integral result that is expected from the input.
\subsection{Adaptive Fold}
The Adaptive API exports an identical interface to fold and reduce partial results, and hence this solution is syntactically similar to \texttt{Rayon Fold}
\subsection{Code}
\begin{verbatim}
pub fn solver_par_split(inp: &[Token]) -> u64 {
    inp.as_parallel_slice()
        .par_split(|tok| *tok == Token::Add)
        .map(|slice| {
            slice.into_par_iter()
                .filter_map(|tok| match tok {
                    Token::Mult | Token::Add => None,
                    Token::Num(i) => Some(i),
                })
                .product::<u64>()
        })
        .sum::<u64>()
}

pub fn solver_par_fold(inp: &[Token]) -> u64 {
    inp.into_par_iter()
        .fold(PartialProducts::new, |mut products, tok| match *tok {
            Token::Num(i) => {
                products.update_product(i);
                products
            }
            Token::Add => {
                products.append_product();
                products
            }
            Token::Mult => products,
        }).reduce(PartialProducts::new, |left, right| left.fuse(&right))
        .evaluate()
}

pub fn solver_adaptive(inp: &[Token], policy: Policy) -> u64 {
    inp.into_adapt_iter()
            .with_policy(policy)
            .fold(PartialProducts::new, |mut p, token| {
                match token {
                    Token::Num(i) => p.update_product(*i),
                    Token::Add => p.append_product(),
                    Token::Mult => {}
                }
                p
            }).reduce(|left, right| left.fuse(&right))
            .evaluate()
}
\end{verbatim}
\section{Speedup curves}
\section{Logs} %[TODO] Decide if need to include the logs
\section{Conclusions}
The performance for \texttt{Rayon Split} was quite unstable. It depended completely on the density of the + operator. This is as expected since the + operator dictates task splitting in the first level, varying it's density would lead to too few or too many tasks and hence change the performance.

The \texttt{Rayon Fold} was only slightly faster than sequential version. As per the logs, this was mainly because of excessive task splitting which lead to a high task creation overhead and also slowed down the computation of each task. Furthermore, the cost of initialising the partial results and updating them didn't get amortized due to the high number of tasks that were created.

The logs reveal that the speedup for \texttt{Adaptive Fold} was sublinear mainly because of lower speed of execution of each parallel task. The idle times were quite low and task creation was much lower than Rayon. However, load seemed to have been balanced more or less effectively. The lower speed of computation can be attributed to the difference in the way Rust optimizes a sequential fold over a tuple versus operations over the PartialProducts struct. Furthermore, the overhead of reduction adds on to the constant factor in the overall linear work in the parallel algorithm.
